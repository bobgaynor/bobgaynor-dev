<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Interactive demo of the Cyber Threat Analyzer - an ML-powered pipeline for detecting brute force attacks in security logs.">
  <title>Cyber Threat Analyzer (CTA) - Interactive Demo</title>
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body>
  <a href="#main-content" class="skip-link">Skip to main content</a>
  <header>
    <nav aria-label="Main navigation">
      <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="../about.html">About</a></li>
        <li><a href="../projects.html">Projects</a></li>
      </ul>
    </nav>
  </header>
  <main id="main-content">
    <h1>Cyber Threat Analyzer (CTA) - Interactive Demo</h1>

    <section id="project-write-up">
      <h2>Project Write-up</h2>
      
      <h3>Summary</h3>
      <p>This project is a complete, end-to-end data pipeline built to demonstrate key skills in Data Engineering, Machine Learning, and MLOps. The core theme is "Signal in the Noise." The application ingests a raw system.log file (99% "noise") and uses a machine learning model to find the 1% "signal" of a brute force attack.</p>
      
      <h3>The Problem/Motivation</h3>
      <p>As a cybersecurity professional, I was inspired by the need to perform manual, deep-dive analysis on anomalous security logs that automated tools often miss. This project demonstrates my ability to: Design end-to-end ML pipelines from raw data to model deployment; Apply machine learning to real-world security problems; and Build production-quality code with proper software engineering practices.</p>
      
      <h3>My Approach</h3>
      <p>The pipeline follows these steps: Raw Logs → Parse & Extract → Threat Intelligence Enrichment → Feature Engineering → ML Classification Model → Signal Report. Key features include: Ingesting and parsing raw, unstructured logs with Python and Regex; Automatically enriching IPs with live threat data from the AbuseIPDB API; and Intelligent caching to avoid re-querying the API.</p>

      <h3>The Results</h3>
      <p>The v1.0 'Noise Filter' (Decision Tree) achieved a Threat Detection Accuracy of 62% on the test set. Key results show API efficiency was improved by intelligent caching which reduced queries by ~90%, and the full pipeline executes in less than 2 seconds. The project is fully reproducible using an environment.yml file and can be run via python main.py. <a href="https://github.com/bobgaynor/cta-noise-filter" target="_blank">[Link to full GitHub Repo]</a></p>
    </section>

    <section id="interactive-demo">
      <h2>Simulated Analysis Demo</h2>
      <label for="ip_score">Suspicion Score (0-100):</label>
      <input type="number" id="ip_score" value="50">
      
      <label for="log_count">Log Entry Count:</label>
      <input type="number" id="log_count" value="15">
      
      <button id="runDemo">Run Threat Filter</button>
      
      <div id="ctaResult" style="margin-top: 20px; padding: 15px; border-radius: 5px;"></div>
    </section>
  </main>

  <script>
    document.getElementById('runDemo').addEventListener('click', function() {
      const ipScoreInput = document.getElementById('ip_score').value;
      const logCountInput = document.getElementById('log_count').value;
      const resultDiv = document.getElementById('ctaResult');

      // Input validation
      const ipScore = parseInt(ipScoreInput, 10);
      const logCount = parseInt(logCountInput, 10);

      if (isNaN(ipScore) || isNaN(logCount)) {
        resultDiv.textContent = 'Error: Please enter valid numbers for both fields.';
        resultDiv.style.backgroundColor = '#fff3cd';
        resultDiv.style.color = '#856404';
        return;
      }

      if (ipScore < 0 || ipScore > 100) {
        resultDiv.textContent = 'Error: Suspicion Score must be between 0 and 100.';
        resultDiv.style.backgroundColor = '#fff3cd';
        resultDiv.style.color = '#856404';
        return;
      }

      if (logCount < 0) {
        resultDiv.textContent = 'Error: Log Entry Count cannot be negative.';
        resultDiv.style.backgroundColor = '#fff3cd';
        resultDiv.style.color = '#856404';
        return;
      }

      let classification = '';

      // Clear previous content safely
      resultDiv.textContent = '';

      if (ipScore >= 70 || logCount >= 20) {
        classification = 'SIGNAL';
        const strongEl = document.createElement('strong');
        strongEl.textContent = classification;
        resultDiv.appendChild(document.createTextNode('Classification: '));
        resultDiv.appendChild(strongEl);
        resultDiv.appendChild(document.createTextNode(` (Brute Force Attack Detected) based on Suspicion Score: ${ipScore} and Log Count: ${logCount}.`));
        resultDiv.style.backgroundColor = '#f8d7da';
        resultDiv.style.color = '#721c24';
      } else {
        classification = 'NOISE';
        const strongEl = document.createElement('strong');
        strongEl.textContent = classification;
        resultDiv.appendChild(document.createTextNode('Classification: '));
        resultDiv.appendChild(strongEl);
        resultDiv.appendChild(document.createTextNode(` (Normal Log Traffic) based on Suspicion Score: ${ipScore} and Log Count: ${logCount}.`));
        resultDiv.style.backgroundColor = '#d4edda';
        resultDiv.style.color = '#155724';
      }
    });
  </script>
</body>
</html>
